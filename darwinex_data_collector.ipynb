{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ef2ff6d",
   "metadata": {},
   "source": [
    "The aim of this nb is to populate a postgresdatabase with Forex data from Darwinex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e368a633",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "%pip install psycopg2\n",
    "import psycopg2\n",
    "\n",
    "PASSWORD=\"\"\n",
    "\n",
    "def open_connection(database=\"darwinex3\"):\n",
    "    #establishing the connection\n",
    "    conn = psycopg2.connect(\n",
    "            database=database,\n",
    "            user='postgres', password=PASSWORD, host='127.0.0.1', port= '5432'\n",
    "    )\n",
    "    conn.autocommit = True\n",
    "    return conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e7436d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add code to connect Darwinex FTP and download the missing days\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fd55e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_extension_timescaledb(dbname):\n",
    "    conn = open_connection(database=dbname)\n",
    "    sql = '''create extension if not exists timescaledb;'''\n",
    "    cursor.execute(sql)\n",
    "    print(\"Configuring timescaledb\")\n",
    "    conn.commit()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e250468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This depends on the timeseriesdb timescale.com\n",
    "# installation docs at https://docs.timescale.com/install/latest/\n",
    "\n",
    "def create_table(pair,side,database,drop=False):\n",
    "    conn = open_connection(database=database)\n",
    "    cursor = conn.cursor()\n",
    "    table_name = f\"d_{pair}_{side}\"\n",
    "    # Avoid droping tables by mistake\n",
    "    if drop:\n",
    "        cursor.execute(f\"DROP TABLE IF EXISTS {table_name}\")        \n",
    "        print(f\"Delete created successfully........for {table_name}\")\n",
    "    \n",
    "    # TODO: If table does not exists\n",
    "    sql =f'''CREATE TABLE d_{pair}_{side}(\n",
    "       TIMESTAMP TIMESTAMP NOT NULL,\n",
    "       DATETIME VARCHAR(15),\n",
    "       {side} FLOAT NOT NULL,\n",
    "       VOL FLOAT\n",
    "    )'''\n",
    "    cursor.execute(sql)    \n",
    "    print(f\"Table {table_name} created successfully........\")    \n",
    "    # create hypertable\n",
    "    sql=f'''select create_hypertable('{table_name}','timestamp');'''\n",
    "    cursor.execute(sql)\n",
    "    print(f\"Table {table_name} created hypertable........\")\n",
    "    conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570f24b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "\n",
    "database = \"darwinex3\"\n",
    "pairs=[\"usdchf\"]\n",
    "\n",
    "for pair in pairs:\n",
    "    side=\"ask\"\n",
    "    create_table(pair,side,database)\n",
    "    side=\"bid\"\n",
    "    create_table(pair,side,database)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68309961",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def get_datetime(fname):\n",
    "    date = fname.split('_')[2]\n",
    "    time =  fname.split('_')[3].split('.')[0]\n",
    "    #print(date,time)\n",
    "    return date+'_'+time\n",
    "\n",
    "def unzip_log_file(full_path):\n",
    "    import gzip    \n",
    "    registers=''\n",
    "    try:\n",
    "        with gzip.open(full_path,'rb') as f:\n",
    "            file_content = f.read()\n",
    "        registers = file_content.decode('ascii').split(\"\\n\")        \n",
    "    except OSError:\n",
    "        print(OSError.errno)\n",
    "        print(f\"Error unzipping {full_path} | \")\n",
    "        return None\n",
    "    return registers\n",
    "    \n",
    "def launch_sql_insert_query(values, table_name, side):    \n",
    "    sql=None\n",
    "    try:\n",
    "        jvalues = \",\".join(values)     \n",
    "        sql = f'''INSERT INTO {table_name}(timestamp,datetime,{side},vol) VALUES {jvalues}'''    \n",
    "        conn = open_connection()\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(sql)        \n",
    "        conn.commit()\n",
    "        conn.close()\n",
    "    except:\n",
    "        #print(\"sql query\",sql)\n",
    "        print(f\"Problem found inserting into table {table_name}\")\n",
    "        return \"KO\"\n",
    "\n",
    "def collect_csv_registers(registers,datehour):\n",
    "    # collect from csv resisters    \n",
    "            \n",
    "    values = []\n",
    "    for reg in registers:\n",
    "        if reg == '':\n",
    "            continue\n",
    "            \n",
    "        sreg = reg.split(',')\n",
    "        \n",
    "        #print(sreg)\n",
    "        \n",
    "        try:\n",
    "            timestamp = datetime.fromtimestamp(float(float(sreg[0])/1000))\n",
    "            \n",
    "            price     = float(sreg[1]) \n",
    "            vol       = int(float(sreg[2]))\n",
    "        \n",
    "            sreg_for_db = f\"('{timestamp}','{datehour}','{price}','{vol}')\"\n",
    "        \n",
    "            #print(sreg_for_db)\n",
    "        \n",
    "            values.append(sreg_for_db)\n",
    "        except ValueError:\n",
    "            print(\"Problem converting data from registers\",sreg)\n",
    "    return values\n",
    "    \n",
    "def insert_into_db(side,pair,fname,path):\n",
    "\n",
    "    full_path = path+\"\\\\\"+fname\n",
    "    \n",
    "    registers = unzip_log_file(full_path)\n",
    "\n",
    "    if registers == None:\n",
    "        return \"KO problem found extrating resigers\"\n",
    "    \n",
    "    datehour = get_datetime(fname)\n",
    "    \n",
    "    values = collect_csv_registers(registers,datehour)\n",
    "\n",
    "    table_name = f\"d_{pair}_{side}\"\n",
    "    \n",
    "    launch_sql_insert_query(values, table_name, side)    \n",
    "        \n",
    "    return \"OK commit \"+fname\n",
    "\n",
    "\n",
    "def insert_bulk_pair(root,pair,side, resume_at=None):\n",
    "    import os\n",
    "    path = os.path.join(root,pair.upper())    \n",
    "    lfiles = os.listdir(path)\n",
    "    assert len(lfiles) > 0\n",
    "    \n",
    "    index_to_resume = None\n",
    "    if resume_at != None:\n",
    "        index_to_resume = resume_at.get(pair,None)\n",
    "\n",
    "    #print(index_to_resume)\n",
    "    for index, fname in enumerate(lfiles):\n",
    "     \n",
    "        if index_to_resume!=None and index_to_resume > index:\n",
    "            #print(f\"{index} skip file {fname}\")\n",
    "            continue            \n",
    "        \n",
    "        if not fname.endswith(\".log.gz\"):\n",
    "            continue\n",
    "        \n",
    "        if side.upper() not in fname:\n",
    "            continue\n",
    "        \n",
    "        is_ok = insert_into_db(side,pair,fname,path)\n",
    "        if(is_ok ==\"KO\"):\n",
    "            print(\"something went wrong\",index)\n",
    "            break\n",
    "        print(datetime.now(), index, is_ok)\n",
    "        \n",
    "        \n",
    "def multiple_inserts(root, pairs, sides, resume_at=None):\n",
    "    for pair in pairs: \n",
    "        for side in sides:\n",
    "            insert_bulk_pair(root,pair,side, resume_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c3759e",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = 'C:\\\\Users\\\\ruben\\\\darwinex_data'\n",
    "resume_at = {}\n",
    "resume_at[\"eurgbp\"] = 15449 # Resume ask at 22880\n",
    "pairs  = ['eurgbp','usdchf'] \n",
    "sides  = ['ask','bid'] \n",
    "multiple_inserts(root,pairs, sides, resume_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc0e9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the way to ingest ms into postgres\n",
    "#datetime.fromtimestamp(float('1506891900032')/1000)\n",
    "\n",
    "#conn = open_connection()\n",
    "#fname='USDCAD_ASK_2020-02-28_19.log.gz'\n",
    "#pair='usdcad'\n",
    "#insert_into_db(side,pair,fname,conn)\n",
    "\n",
    "#fname=path+'\\\\USDCAD_ASK_2020-02-28_19.log.gz'\n",
    "#with gzip.open(full_path,'rb') as f:\n",
    "#    file_content = f.read()\n",
    "#print(file_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}